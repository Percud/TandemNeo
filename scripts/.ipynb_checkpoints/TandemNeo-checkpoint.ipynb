{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#python3.7\n",
    "#anaconda3\n",
    "\n",
    "#conda create -n myenv3.7 python=3.7\n",
    "#conda activate myenv3.7 \n",
    "#conda install...\n",
    "\n",
    "#clustalo            0.1.2\n",
    "#blastp \n",
    "\n",
    "#biopython           1.78\n",
    "#ipykernel           5.3.4\n",
    "#ipython             7.19.0\n",
    "#ipython-genutils    0.2.0\n",
    "#json5               0.9.5\n",
    "#jupyterlab          2.2.6\n",
    "#matplotlib          3.3.2\n",
    "#natsort             7.1.0\n",
    "#numpy               1.19.2\n",
    "#pandas              1.1.5\n",
    "#pymol               2.4.1\n",
    "#requests            2.25.1\n",
    "#urllib3             1.26.2\n",
    "#xmltodict           0.12.0\n",
    "\n",
    "# informati sui sistemi docker\n",
    "# il setup.py dei pacchetti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modules and config import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modules and congig import\n",
    "\n",
    "import os, sys, gzip, json\n",
    "import pandas as pd\n",
    "from   multiprocessing import Pool, Manager\n",
    "from   itertools       import product\n",
    "from   Bio             import SeqIO\n",
    "\n",
    "from   specieinfo      import assemblies\n",
    "from   specieinfo      import specieinfo      as si\n",
    "from   download        import download        as dl\n",
    "from   mainisoforms    import mainisoforms    as mi\n",
    "from   duplications    import duplications    as dup\n",
    "from   orthology       import ortho           as ort \n",
    "from   faforalignments import faforalignments as ffal\n",
    "from   database        import database        as db\n",
    "from   database        import dbinfo\n",
    "from   alignments      import alignments      as al\n",
    "from   features        import features        as feat\n",
    "\n",
    "cwd = os.path.dirname(os.getcwd())\n",
    "sys.path.append(cwd)\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Working directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(cwd + '/appris')\n",
    "os.mkdir(cwd + '/alignments')\n",
    "os.mkdir(cwd + '/alignments/tandem')\n",
    "os.mkdir(cwd + '/alignments/divergent')\n",
    "os.mkdir(cwd + '/alignments/convergent')\n",
    "os.mkdir(cwd + '/blast_queries')\n",
    "os.mkdir(cwd + '/duplications')\n",
    "os.mkdir(cwd + '/fa')\n",
    "os.mkdir(cwd + '/gtf')\n",
    "os.mkdir(cwd + '/main')\n",
    "os.mkdir(cwd + '/orthologues')\n",
    "os.mkdir(cwd + '/features')\n",
    "os.mkdir(cwd + '/clustering')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Species info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggiungere tutta la filogenesi, sarebbe meglio avere la gerarchia filogenetica nel multindex del database ortologhi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not have_list:\n",
    "\n",
    "    species = [a['name'] for a in assemblies['species']]       # collect all available species name in Ensembl database\n",
    "    slist = [si(s).allinfo for s in species]                   # specieinfo class for each of those species name\n",
    "\n",
    "    df = pd.DataFrame(slist, columns=[\n",
    "                                    'Class',\n",
    "                                    'Order',\n",
    "                                    'Genus',\n",
    "                                    'Specie',\n",
    "                                    'Publications',\n",
    "                                    'Taxid',\n",
    "                                    'Assembly']).dropna()      # writing a dataframe with all collected informations\n",
    "    df = df[df['Class'].isin(rf)]                              # filtering the dataframe for classes specified withing the config file\n",
    "    df['Publications'] = df['Publications'].astype(int)\n",
    "    df['Genus']        = df['Genus'].str.capitalize()          # capitalize genus value\n",
    "    df = df.sort_values('Publications', ascending=False)       # sorting for the publications\n",
    "    if mo:\n",
    "        df = df.groupby('Order').head(mo)                      # limiting the max number of orders to collect (specified in config)\n",
    "    if mg:\n",
    "        df = df.groupby('Genus', sort=False).head(mg)          # same for the genres\n",
    "    df = df.sort_values(['Class', 'Order'])                    # last sorting for the final dataframe\n",
    "    df.to_csv(cwd + '/species/species_list.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. FASTAs and GTFs download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = pd.read_csv(cwd + '/species/species_list.csv')            # open species containing file\n",
    "fa = [l[2] + '_' + l[3] for l in ls.values.tolist()]           # write a list containing all the specie names for the fasta files\n",
    "gtf = rs                                                       # write a list containing all the specie names for the gtf files\n",
    "\n",
    "pool = Pool(threads)                                           # activating the dl function in multiprocessing\n",
    "pool.starmap(dl.downl, product(gtf, ['gtf']))                  # starmap multiprocessing accepts tuple with arguments [('Homo_sapiens', 'gtf'), ('Gallus_gallus', 'gtf'), etc...]\n",
    "pool.starmap(dl.downl, product(fa, ['fa']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Main isoforms and BLASTP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mainblast(s, n, e, h, t):\n",
    "    mi.tofa(s)                                                 # activating tofa function, write a principal isoforms containing .fa file\n",
    "    mi.totsv(s)                                                # activating totsv function, write a principal isoforms, sorted over the genome, containing .tsv file\n",
    "    mi.blast(s, n, e, h, t)                                    # performing an intraspecie blastP\n",
    "\n",
    "blast_args = [num_threads,\n",
    "              evalue,\n",
    "              max_hsps,\n",
    "              max_target_seqs]\n",
    "\n",
    "pool = Pool(threads)                                           # activating the dl function in multiprocessing\n",
    "args = [tuple([s] + blast_args) for s in rs]\n",
    "pool.starmap(mainblast, args)                                  # starmap multiprocessing accepts tuple with arguments [('Homo_sapiens', 20, '10e-6', 1, 5), ('Gallus_gallus', 20, '10e-6', 1, 5), etc...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Duplications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tocsv(s, k):                                               # saving a .tsv file containing a list of duplications filtered for specie e duplication kind\n",
    "\n",
    "    dups = dup.duplist(s, k)                                   # retrieving the accessions list for specie and duplication kind\n",
    "    for l in dups:\n",
    "        path = cwd + '/duplications/'\n",
    "        file = path + s + '_' + k + '.tsv'\n",
    "        print(*l, sep='\\t', file=open(file, 'a'))              # writing duplicated pair in a tsv file\n",
    "\n",
    "Pool(threads).starmap(tocsv, product(rs, dups))                # activating the tocsv function in multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Orthology (COMPARA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forquery(ID, d):\n",
    "    \n",
    "    file = d + '_no_filter.csv'\n",
    "    path = cwd + '/orthologues/' + file\n",
    "    df   = ort.df(ID[0], True)                                 # per ogni ID fornito scarica la lista degli ortologhi in formato dataframe, se viene fornita una lista di specie viene filtrato per queste\n",
    "    df['orthogroup'] = ID[1]                                   # assegna un numero corrispondende all'ortogruppo in base all'ordine di apparizione nel genoma dell'ID in esame\n",
    "    df   = df.values.tolist()\n",
    "\n",
    "    for l in df:\n",
    "        print(*l, sep=';', file=open(path, 'a'))               # dopo la conversione in lista delle righe del dataframe, vengono stampati al momento i risultati in un file con tutte le informazioni non filtrate\n",
    "        \n",
    "def forspecie(rs, d):\n",
    "        \n",
    "    dups_df = ort.mergedups(rs, d)[[8, 10]]                    # unisce i dataframe contenenti i geni duplicati di tutte le specie di riferimento per ciascun tipo di duplicazione\n",
    "    IDS = [l for l in dups_df.values.tolist()]                 # recupera tutti gli ID e i numeri degli ortogruppi assegnati per ogni tipo di duplicazione\n",
    "    Pool(5).starmap(forquery, product(IDS, [d]))               # attiva la funzione (in multiprocessing) forquery per ogni ID presente nel dataframe nato dall'unione precedente\n",
    "\n",
    "dups = ['convergent', 'divergent']\n",
    "for d in dups:\n",
    "    file = d + '_no_filter.csv'\n",
    "    path = cwd + '/orthologues/' + file\n",
    "    forspecie(rs, d)                                           # attiva la funzione for specie per ogni specie di riferimento e tipo di duplicazione\n",
    "    ort.brh(path)                                              # brh interno nel dataframe di ortologia ottenuto, altri commenti presenti in orthology.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### aggiungi a orthology\n",
    "\n",
    "database = json.load(open(cwd + '/database.json'))\n",
    "\n",
    "df = pd.read_table('/Users/carloderito/Desktop/TandemNeo/orthologues/tandem.csv', sep=';').set_index(['Class', 'Order', 'Species'])\n",
    "df = df.applymap(lambda x: x if str(x) == 'nan' or not x in database.keys() else database.get(x)['gene id'])\n",
    "df.to_csv('/Users/carloderito/Desktop/TandemNeo/orthologues/tandem_genes.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df    = db.orthodf('Tandem')                                   # opening orthologues dataframe for:\n",
    "slist = df['Species'].values.tolist()                          # obtaining species list\n",
    "\n",
    "manager = Manager()\n",
    "data    = manager.dict()\n",
    "\n",
    "def db_func(s):\n",
    " \n",
    "    path   = cwd + '/fa/' + s + '.fa.gz'\n",
    "    handle = gzip.open(path, 'rt')\n",
    "    fastas = list(SeqIO.parse(handle, \"fasta\"))                # opening file.fa --> storing in a list\n",
    "\n",
    "    orthos = db.aclist(s)                                      # accessions list from the orthologues tab\n",
    "    f = [l for l in fastas \n",
    "         if l.id.split('.')[0] in orthos]                      # intersection between orthologues accession list and fastas\n",
    "\n",
    "    for l in f:\n",
    "        data.update(db.info(l))                                # activating database class info function\n",
    "        \n",
    "Pool(threads).map(db_func, \n",
    "    [s for s in slist])\n",
    "        \n",
    "json.dump(data.copy(), open(cwd + '/database.json', 'w'))      # dumping json database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. FASTAs for alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in dups:                                                 # for each kind of duplication\n",
    "\n",
    "    df    = db.orthodf(d)                                      # open and keep in memory the orthologues dataframe\n",
    "    pairs = ffal.pairslist(d)                                  # write a list containing the orthologues dataframe column indexes corresponding to orthogroup pairs \n",
    "    suff  = db.suffixes()                                      # write a dictionary containing the species references based on accessions Ensembl coding {ENSP0: 'Homo_sapiens'}\n",
    "    js    = json.load(open(cwd + '/database.json'))            # open the local database wrote in step 6\n",
    "    \n",
    "    for p in pairs:                                            # iterating over dataframe column indexes\n",
    "        ffal.printfa(df, p, suff, js, d)                       # writing FASTA file (1.fa will contain the FASTA corresponding to columns 1A and 1B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_proteome = pd.read_csv('https://www.uniprot.org/uniprot/?query=organism:9606&columns=id,entry%20name,reviewed,protein%20names,genes,organism,length,ec&format=tab', sep = '\\t')\n",
    "sums = []\n",
    "\n",
    "for d in dups:\n",
    "    \n",
    "    folder = 'alignments/' + d\n",
    "    ogroups = al.fanum(folder, '.fa')\n",
    "    \n",
    "    for o in ogroups:                                          # for each orthogroup\n",
    "        \n",
    "        fa   = 'alignments/' + d + '/' + str(o) + '.fa'        # FASTA file path\n",
    "        faln = 'alignments/' + d + '/' + str(o) + '.fasta'     # Aligned FASTA file path\n",
    "        al.clustifcov(fa, faln, th_coverage)                   # perform a clustalo if sequence lenghts coverage is higher than config threshold\n",
    "        \n",
    "    manager = Manager()\n",
    "    logs = manager.dict()\n",
    "    \n",
    "    def log(ogroup, srefs, matrix):\n",
    "        \n",
    "        try:\n",
    "            faln     = folder + '/' + str(ogroup) + '.fasta'   # Aligned FASTA file path\n",
    "            falnfile = al.alignmentfile(faln)                  # aligned FASTA file\n",
    "            if not ogroup in logs.keys():\n",
    "                log  = al.log(falnfile, srefs, matrix)         # return a log containing alignments informations\n",
    "                logs.update({ogroup: log})                     # storing those information inside a Manager dictionary for multiprocessing\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    Pool(threads).starmap(                                     # activating log function in multiprocessing\n",
    "        log, product(\n",
    "            ogroups, [srefs], [matrix]))\n",
    "        \n",
    "    json.dump(logs.copy(), open(\n",
    "        cwd + '/' + folder + '/' + d + '.json', 'w'))          # dumping those informations inside a json file\n",
    "    \n",
    "    f=al.threshold_aln(logs, str(alignment_threshold))\n",
    "    f['kind'] = d\n",
    "    score_1=feat.convert_ac(f['ensembl_ac_protein'].drop_duplicates().dropna().tolist(), 'ENSEMBL_PRO_ID', 'ACC').rename(columns={'From':'ensembl_ac_protein','To':'uniprot_ac'}).merge(f)\n",
    "    tabella_score_1_uniprot=pd.merge(human_proteome[['Entry','Gene names','Protein names','EC number']], score_1, left_on='Entry', right_on='uniprot_ac')\n",
    "    sums.append(tabella_score_1_uniprot.\n",
    "                astype({'ensembl_num':'float64'}).\n",
    "                sort_values(['total_scores>' + str(alignment_threshold), 'ensembl_num'], ascending=[False,True]).\n",
    "                drop('uniprot_ac', axis=1))\n",
    "\n",
    "pd.concat(sums).to_csv(cwd + '/alignments/sum_of_scores_' + str(alignment_threshold) + '.csv', sep=';',index=False)\n",
    "\n",
    "### DA RIPROVARE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aggiungi range delle posizioni nella tabella"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in dups:\n",
    "\n",
    "    ortholist = dbinfo.ids_to(                                 # IDs conversion from protein to gene \n",
    "        features_ref_specie, d, 'gene')\n",
    "    converted = feat.convert_id(                               # IDs conversion from ENSEMBL to Uniprot\n",
    "        'ENSEMBL_ID', 'ACC', ortholist)\n",
    "    converted_IDS = [v for k,v in converted.items()            # storing in a list all uniprot IDS \n",
    "                     if not 'ENS' in v]\n",
    "\n",
    "    manager = Manager()\n",
    "    appended_data = manager.list()\n",
    "    def getfeaturesparallel(k):\n",
    "        data = feat.getfeatures(k)                             # using features class getfeatures function to retrieve a complete features dataset for each ID\n",
    "        appended_data.append(data)\n",
    "    Pool(threads).map(getfeaturesparallel, converted_IDS)      # activating getfeaturesparallel function in multiprocessing\n",
    "\n",
    "    allfeatures = pd.concat(appended_data)                     # concatenated dataframe with features infos\n",
    "\n",
    "    path = cwd + '/alignments/' + d + '/'\n",
    "    aln = json.load(open(path + d + '.json'))                  # opening the json format alignments containing file\n",
    "    alns = al.threshold_aln(\n",
    "        aln, alignment_threshold)                              # set a threshold based on the alignment scores and return a dataframe\n",
    "    alns = feat.add_genes_ids(alns, converted)                 # add more infos in the dataframe\n",
    "    \n",
    "    features = feat.intersect_alns_features(\n",
    "        alns, allfeatures)                                     # return an intersection between alignments dataframe and allfeatures dataframe\n",
    "    # --> feat.filter(allfeatures)\n",
    "    features.to_csv(cwd + '/features/' + d + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### download_pdb\n",
    "\n",
    "os.chdir(cwd + '/clustering/')\n",
    "pdb_ca = get_coord_ca(clust_ref_specie)\n",
    "\n",
    "for d in dups:\n",
    "\n",
    "    clustering(pdb_ca,\n",
    "               clust_ref_specie + '/' + clust_ref_specie + '.csv', \n",
    "               json.load(open(cwd + '/alignments/' + d + '/' + d + '.json')),\n",
    "               alignment_threshold, \n",
    "               clust_mean_samples, \n",
    "               clust_eps)\n",
    "    \n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impor alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tabella generale con types e categories e da questa scegliamo per -inclusione- le voci che ci interessano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "              \n",
    "df = pd.read_table('/Users/carloderito/Desktop/TandemNeo/features/tandem.csv', sep=',')\n",
    "#df = df.drop(columns=['Unnamed: 0'])\n",
    "df[df['type'] == 'ACT_SITE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['description'] == '4-hydroxyproline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['category'] == 'PTM'].groupby('description').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['category'] == 'PTM']['description'].drop_duplicates().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_table('/Users/carloderito/Downloads/features_threshold_1 - Features.csv', sep=',', header=None)\n",
    "df2[df2[9] == 'MUTAGENESIS'].drop_duplicates(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = cwd + '/alignments/' + d + '/'\n",
    "#x = json.load(open(path + d + '.json')) \n",
    "\n",
    "for aln in x.items():\n",
    "    if aln[0] == '27':\n",
    "        for p in x[aln[0]]['Positions'].items():\n",
    "            if p[1]['Score difference']>1:\n",
    "                for tag in p[1].items():\n",
    "                    #print(tag[0])\n",
    "                    if type(tag[1])== dict:\n",
    "                        for ac in p[1][tag[0]].keys():\n",
    "                            #if ac == 'ENSP00000226279':\n",
    "                                #if type(ac[1])== dict:\n",
    "                                #print(aln[0],p[0],tag[0],ac[0],ac[1]['Positions'],ac[1]['Residue'],tag[1]['Column'],p[1]['Score difference'],)\n",
    "                            print(tag, p[1]['Score difference'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/carloderito/anaconda3/envs/myenv3.7/lib/python3.7/distutils/fancy_getopt.py\", line 233, in getopt\n",
      "    opts, args = getopt.getopt(args, short_opts, self.long_opts)\n",
      "  File \"/Users/carloderito/anaconda3/envs/myenv3.7/lib/python3.7/getopt.py\", line 95, in getopt\n",
      "    opts, args = do_shorts(opts, args[0][1:], shortopts, args[1:])\n",
      "  File \"/Users/carloderito/anaconda3/envs/myenv3.7/lib/python3.7/getopt.py\", line 195, in do_shorts\n",
      "    if short_has_arg(opt, shortopts):\n",
      "  File \"/Users/carloderito/anaconda3/envs/myenv3.7/lib/python3.7/getopt.py\", line 211, in short_has_arg\n",
      "    raise GetoptError(_('option -%s not recognized') % opt, opt)\n",
      "getopt.GetoptError: option -f not recognized\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/carloderito/anaconda3/envs/myenv3.7/lib/python3.7/distutils/core.py\", line 134, in setup\n",
      "    ok = dist.parse_command_line()\n",
      "  File \"/Users/carloderito/anaconda3/envs/myenv3.7/lib/python3.7/distutils/dist.py\", line 475, in parse_command_line\n",
      "    args = parser.getopt(args=self.script_args, object=self)\n",
      "  File \"/Users/carloderito/anaconda3/envs/myenv3.7/lib/python3.7/distutils/fancy_getopt.py\", line 235, in getopt\n",
      "    raise DistutilsArgError(msg)\n",
      "distutils.errors.DistutilsArgError: option -f not recognized\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/carloderito/anaconda3/envs/myenv3.7/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3418, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-8-3c5ecc58a6ac>\", line 25, in <module>\n",
      "    python_requires='>=3.7',\n",
      "  File \"/Users/carloderito/anaconda3/envs/myenv3.7/lib/python3.7/site-packages/setuptools/__init__.py\", line 153, in setup\n",
      "    return distutils.core.setup(**attrs)\n",
      "  File \"/Users/carloderito/anaconda3/envs/myenv3.7/lib/python3.7/distutils/core.py\", line 136, in setup\n",
      "    raise SystemExit(gen_usage(dist.script_name) + \"\\nerror: %s\" % msg)\n",
      "SystemExit: usage: ipykernel_launcher.py [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]\n",
      "   or: ipykernel_launcher.py --help [cmd1 cmd2 ...]\n",
      "   or: ipykernel_launcher.py --help-commands\n",
      "   or: ipykernel_launcher.py cmd --help\n",
      "\n",
      "error: option -f not recognized\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/carloderito/anaconda3/envs/myenv3.7/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1170, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/carloderito/anaconda3/envs/myenv3.7/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/carloderito/anaconda3/envs/myenv3.7/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/carloderito/anaconda3/envs/myenv3.7/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "AttributeError: 'tuple' object has no attribute 'tb_frame'\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mGetoptError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/myenv3.7/lib/python3.7/distutils/fancy_getopt.py\u001b[0m in \u001b[0;36mgetopt\u001b[0;34m(self, args, object)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m             \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetopt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshort_opts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong_opts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgetopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myenv3.7/lib/python3.7/getopt.py\u001b[0m in \u001b[0;36mgetopt\u001b[0;34m(args, shortopts, longopts)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_shorts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshortopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myenv3.7/lib/python3.7/getopt.py\u001b[0m in \u001b[0;36mdo_shorts\u001b[0;34m(opts, optstring, shortopts, args)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptstring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptstring\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptstring\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mshort_has_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshortopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0moptstring\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myenv3.7/lib/python3.7/getopt.py\u001b[0m in \u001b[0;36mshort_has_arg\u001b[0;34m(opt, shortopts)\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mshortopts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m':'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mGetoptError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'option -%s not recognized'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mGetoptError\u001b[0m: option -f not recognized",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mDistutilsArgError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/myenv3.7/lib/python3.7/distutils/core.py\u001b[0m in \u001b[0;36msetup\u001b[0;34m(**attrs)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mok\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_command_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mDistutilsArgError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myenv3.7/lib/python3.7/distutils/dist.py\u001b[0m in \u001b[0;36mparse_command_line\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_aliases\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'licence'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'license'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetopt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscript_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0moption_order\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_option_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myenv3.7/lib/python3.7/distutils/fancy_getopt.py\u001b[0m in \u001b[0;36mgetopt\u001b[0;34m(self, args, object)\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgetopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mDistutilsArgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDistutilsArgError\u001b[0m: option -f not recognized",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-3c5ecc58a6ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m     ],\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mpython_requires\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'>=3.7'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     )\n",
      "\u001b[0;32m~/anaconda3/envs/myenv3.7/lib/python3.7/site-packages/setuptools/__init__.py\u001b[0m in \u001b[0;36msetup\u001b[0;34m(**attrs)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0m_install_setup_requires\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdistutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myenv3.7/lib/python3.7/distutils/core.py\u001b[0m in \u001b[0;36msetup\u001b[0;34m(**attrs)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mDistutilsArgError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mSystemExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscript_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\nerror: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemExit\u001b[0m: usage: ipykernel_launcher.py [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]\n   or: ipykernel_launcher.py --help [cmd1 cmd2 ...]\n   or: ipykernel_launcher.py --help-commands\n   or: ipykernel_launcher.py cmd --help\n\nerror: option -f not recognized",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myenv3.7/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2037\u001b[0m                            'the full traceback.\\n']\n\u001b[1;32m   2038\u001b[0m                     stb.extend(self.InteractiveTB.get_exception_only(etype,\n\u001b[0;32m-> 2039\u001b[0;31m                                                                      value))\n\u001b[0m\u001b[1;32m   2040\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2041\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myenv3.7/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mget_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mexception\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m         \"\"\"\n\u001b[0;32m--> 823\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mListTB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructured_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshow_exception_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myenv3.7/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     chained_exceptions_tb_offset, context)\n\u001b[1;32m    701\u001b[0m                 \u001b[0;34m+\u001b[0m \u001b[0mchained_exception_message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m                 + out_list)\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myenv3.7/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1435\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1436\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1437\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myenv3.7/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1335\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1337\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1338\u001b[0m             )\n\u001b[1;32m   1339\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Minimal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myenv3.7/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m-> 1194\u001b[0;31m                                                                tb_offset)\n\u001b[0m\u001b[1;32m   1195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[0;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myenv3.7/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myenv3.7/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "import os\n",
    "cwd = '/Users/carloderito/Desktop/GitHub/TandemNeo/'\n",
    "os.chdir(cwd)\n",
    "\n",
    "import setuptools\n",
    "\n",
    "with open(\"README.md\", \"r\", encoding=\"utf-8\") as fh:\n",
    "    long_description = fh.read()\n",
    "\n",
    "setuptools.setup(\n",
    "    name=\"TandemNeo\",\n",
    "    version=\"0.0.1\",\n",
    "    author=\"Example Author\",\n",
    "    author_email=\"author@example.com\",\n",
    "    description=\"Neofunctionalization of duplicated genes\",\n",
    "    long_description=long_description,\n",
    "    long_description_content_type=\"Analysis of neofunctionalization following gene tandem duplication in vertebrate evolution\",\n",
    "    url=\"https://github.com/Percud/TandemNeo\",\n",
    "    packages=setuptools.find_packages(),\n",
    "    classifiers=[\n",
    "        \"Programming Language :: Python :: 3\",\n",
    "        #\"License :: OSI Approved :: MIT License\",\n",
    "        \"Operating System :: OS Independent\",\n",
    "    ],\n",
    "    python_requires='>=3.7',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv3.7",
   "language": "python",
   "name": "myenv3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
